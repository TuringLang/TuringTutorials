{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using Gaussian Process\n",
    "\n",
    "This Turing tutorial is ported from the Edward tutorial on the same topic: http://edwardlib.org/tutorials/supervised-classification\n",
    "\n",
    "In supervised learning, the task is to infer hidden structure from\n",
    "labeled data, comprised of training examples $\\{(x_n, y_n)\\}$.\n",
    "Classification means the output $y$ takes discrete values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Turing and Distributions.\n",
    "using Turing, Distributions\n",
    "\n",
    "# Import RDatasets.\n",
    "using RDatasets\n",
    "\n",
    "# We need a logit function, which is provided by StatsFuns.\n",
    "using StatsFuns: logit\n",
    "\n",
    "# We need Cholesky matrix decomposition provided by LinearAlgebra\n",
    "using LinearAlgebra\n",
    "\n",
    "# We need Radial Basis Kernel provided by MLKernels\n",
    "using MLKernels\n",
    "\n",
    "# Import MCMCChain, Plots, and StatPlots for visualizations and diagnostics.\n",
    "using MCMCChain, Plots, StatsPlots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Use the\n",
    "[crabs data set](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/crabs.html) from the RDatasets package,\n",
    "which consists of morphological measurements on a crab species. We\n",
    "are interested in predicting whether a given crab has the color form\n",
    "blue (encoded as 0) or orange (encoded as 1). We use all the numeric features\n",
    "in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Sp</th><th>Sex</th><th>Index</th><th>FL</th><th>RW</th><th>CL</th><th>CW</th><th>BD</th></tr><tr><th></th><th>Categorical…</th><th>Categorical…</th><th>Int32</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 8 columns</p><tr><th>1</th><td>B</td><td>M</td><td>1</td><td>8.1</td><td>6.7</td><td>16.1</td><td>19.0</td><td>7.0</td></tr><tr><th>2</th><td>B</td><td>M</td><td>2</td><td>8.8</td><td>7.7</td><td>18.1</td><td>20.8</td><td>7.4</td></tr><tr><th>3</th><td>B</td><td>M</td><td>3</td><td>9.2</td><td>7.8</td><td>19.0</td><td>22.4</td><td>7.7</td></tr><tr><th>4</th><td>B</td><td>M</td><td>4</td><td>9.6</td><td>7.9</td><td>20.1</td><td>23.1</td><td>8.2</td></tr><tr><th>5</th><td>B</td><td>M</td><td>5</td><td>9.8</td><td>8.0</td><td>20.3</td><td>23.0</td><td>8.2</td></tr><tr><th>6</th><td>B</td><td>M</td><td>6</td><td>10.8</td><td>9.0</td><td>23.0</td><td>26.5</td><td>9.8</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& Sp & Sex & Index & FL & RW & CL & CW & BD\\\\\n",
       "\t\\hline\n",
       "\t& Categorical… & Categorical… & Int32 & Float64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & B & M & 1 & 8.1 & 6.7 & 16.1 & 19.0 & 7.0 \\\\\n",
       "\t2 & B & M & 2 & 8.8 & 7.7 & 18.1 & 20.8 & 7.4 \\\\\n",
       "\t3 & B & M & 3 & 9.2 & 7.8 & 19.0 & 22.4 & 7.7 \\\\\n",
       "\t4 & B & M & 4 & 9.6 & 7.9 & 20.1 & 23.1 & 8.2 \\\\\n",
       "\t5 & B & M & 5 & 9.8 & 8.0 & 20.3 & 23.0 & 8.2 \\\\\n",
       "\t6 & B & M & 6 & 10.8 & 9.0 & 23.0 & 26.5 & 9.8 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ Sp           │ Sex          │ Index │ FL      │ RW      │ CL      │\n",
       "│     │ \u001b[90mCategorical…\u001b[39m │ \u001b[90mCategorical…\u001b[39m │ \u001b[90mInt32\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼──────────────┼──────────────┼───────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ B            │ M            │ 1     │ 8.1     │ 6.7     │ 16.1    │\n",
       "│ 2   │ B            │ M            │ 2     │ 8.8     │ 7.7     │ 18.1    │\n",
       "│ 3   │ B            │ M            │ 3     │ 9.2     │ 7.8     │ 19.0    │\n",
       "│ 4   │ B            │ M            │ 4     │ 9.6     │ 7.9     │ 20.1    │\n",
       "│ 5   │ B            │ M            │ 5     │ 9.8     │ 8.0     │ 20.3    │\n",
       "│ 6   │ B            │ M            │ 6     │ 10.8    │ 9.0     │ 23.0    │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset(\"MASS\", \"crabs\")\n",
    "first(data, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column for target defualted to zero.\n",
    "data[:Colour] = 0.0\n",
    "\n",
    "for i in 1:length(data.Sp)\n",
    "    # If a row's \"Sp\" columns say \"O\" for orange, set them to 1 in our new columns.\n",
    "    data[:Colour][i] = (data[:Sp][i] == \"B\" ? 0.0 : 1.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 100\n",
      "Number of features: 5"
     ]
    }
   ],
   "source": [
    "# Note that we sample alternate points because the first and last \n",
    "# 100 in the crbas dataset of RDatasets belong to same class\n",
    "\n",
    "# Create our labels. These are the values we are trying to predict.\n",
    "y_train = data[1:2:end, :Colour]\n",
    "\n",
    "# Get the list of columns to keep.\n",
    "remove_names = filter(x->!in(x, [:Sp, :Sex, :Index, :Colour]), names(data))\n",
    "\n",
    "# Filter the train data\n",
    "X_train = Matrix{Real}(data[1:2:end,remove_names]);\n",
    "\n",
    "N, D = size(X_train)\n",
    "\n",
    "println(\"Number of data points: \", N)\n",
    "print(\"Number of features: \", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "A Gaussian process is a powerful object for modeling nonlinear\n",
    "relationships between pairs of random variables. It defines a distribution over\n",
    "(possibly nonlinear) functions, which can be applied for representing\n",
    "our uncertainty around the true functional relationship.\n",
    "Here we define a Gaussian process model for classification\n",
    "(Rasumussen & Williams, 2006).\n",
    "\n",
    "Formally, a distribution over functions $f:\\mathbb{R}^D\\to\\mathbb{R}$ can be specified\n",
    "by a Gaussian process\n",
    "$$\n",
    "\\begin{align*}\n",
    "  p(f)\n",
    "  &=\n",
    "  \\mathcal{GP}(f\\mid \\mathbf{0}, k(\\mathbf{x}, \\mathbf{x}^\\prime)),\n",
    "\\end{align*}\n",
    "$$\n",
    "whose mean function is the zero function, and whose covariance\n",
    "function is some kernel which describes dependence between\n",
    "any set of inputs to the function.\n",
    "\n",
    "Given a set of input-output pairs\n",
    "$\\{\\mathbf{x}_n\\in\\mathbb{R}^D,y_n\\in\\mathbb{R}\\}$,\n",
    "the likelihood can be written as a multivariate normal\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{y})\n",
    "  &=\n",
    "  \\text{Normal}(\\mathbf{y} \\mid \\mathbf{0}, \\mathbf{K})\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{K}$ is a covariance matrix given by evaluating\n",
    "$k(\\mathbf{x}_n, \\mathbf{x}_m)$ for each pair of inputs in the data\n",
    "set.\n",
    "\n",
    "The above applies directly for regression where $\\mathbb{y}$ is a\n",
    "real-valued response, but not for (binary) classification, where $\\mathbb{y}$\n",
    "is a label in $\\{0,1\\}$. To deal with classification, we interpret the\n",
    "response as latent variables which is squashed into $[0,1]$. We then\n",
    "draw from a Bernoulli to determine the label, with probability given\n",
    "by the squashed value.\n",
    "\n",
    "Define the likelihood of an observation $(\\mathbf{x}_n, y_n)$ as\n",
    "\n",
    "\\begin{align*}\n",
    "  p(y_n \\mid \\mathbf{z}, x_n)\n",
    "  &=\n",
    "  \\text{Bernoulli}(y_n \\mid \\text{logit}^{-1}(\\mathbf{x}_n^\\top \\mathbf{z})).\n",
    "\\end{align*}\n",
    "\n",
    "Define the prior to be a multivariate normal\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{z})\n",
    "  &=\n",
    "  \\text{Normal}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{K}),\n",
    "\\end{align*}\n",
    "\n",
    "with covariance matrix given as previously stated.\n",
    "\n",
    "Let's build the model in Turing. We use a radial basis function (RBF)\n",
    "kernel, also known as the squared exponential or exponentiated\n",
    "quadratic. It returns the kernel matrix evaluated over all pairs of\n",
    "data points; we then Cholesky decompose the matrix to parameterize the\n",
    "multivariate normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(z)\n",
    "  return 1.0 ./ (1.0 .+ exp(-z))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian Process classification\n",
    "@model gp_classification(x, y, n) = begin\n",
    "    \n",
    "    # Calculate distance matrix using Radial Basis Kernel\n",
    "    distmat = RadialBasisKernel(x)\n",
    "    \n",
    "    # Cholesky decompose the matrix to parameterize the normal distribution\n",
    "    cov = cholesky(distmat).L\n",
    "    \n",
    "    # Define the prior to be a multivariate normal\n",
    "    logits ~ MvNormal(0, cov)\n",
    "    \n",
    "    # Get probabilities for classification from the prior\n",
    "    probs = sigmoid(logits)\n",
    "    \n",
    "    # For classfication treat response as latent variable squashed to [0,1]\n",
    "    for i = 1:n\n",
    "        y[i] ~ Bernoulli(probs[i])\n",
    "    end\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Perform approximate inference using No U-Turn Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching SquaredExponentialKernel(::Array{Real,2})\nClosest candidates are:\n  SquaredExponentialKernel() at /home/sheshank/.julia/packages/MLKernels/DqEdF/src/kernelfunctions/mercer/squaredexponential.jl:23\n  SquaredExponentialKernel(!Matched::T<:Real) where T<:Real at /home/sheshank/.julia/packages/MLKernels/DqEdF/src/kernelfunctions/mercer/squaredexponential.jl:23",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching SquaredExponentialKernel(::Array{Real,2})\nClosest candidates are:\n  SquaredExponentialKernel() at /home/sheshank/.julia/packages/MLKernels/DqEdF/src/kernelfunctions/mercer/squaredexponential.jl:23\n  SquaredExponentialKernel(!Matched::T<:Real) where T<:Real at /home/sheshank/.julia/packages/MLKernels/DqEdF/src/kernelfunctions/mercer/squaredexponential.jl:23",
      "",
      "Stacktrace:",
      " [1] macro expansion at ./In[10]:4 [inlined]",
      " [2] (::getfield(Main, Symbol(\"###inner_function#395#17\")){Array{Real,2},Int64})(::Turing.Core.VarReplay.VarInfo, ::Turing.SampleFromUniform, ::Turing.Model{Tuple{:logits},Tuple{:y},getfield(Main, Symbol(\"###inner_function#395#17\")){Array{Real,2},Int64},NamedTuple{(:y,),Tuple{Array{Float64,1}}},NamedTuple{(:y,),Tuple{Symbol}}}) at /home/sheshank/.julia/packages/Turing/izlov/src/core/compiler.jl:388",
      " [3] #call#3 at /home/sheshank/.julia/packages/Turing/izlov/src/Turing.jl:62 [inlined]",
      " [4] Model at /home/sheshank/.julia/packages/Turing/izlov/src/Turing.jl:62 [inlined]",
      " [5] #sample#37(::Bool, ::Nothing, ::Int64, ::Nothing, ::Function, ::Turing.Model{Tuple{:logits},Tuple{:y},getfield(Main, Symbol(\"###inner_function#395#17\")){Array{Real,2},Int64},NamedTuple{(:y,),Tuple{Array{Float64,1}}},NamedTuple{(:y,),Tuple{Symbol}}}, ::NUTS{Turing.Core.ForwardDiffAD{40},Union{}}) at /home/sheshank/.julia/packages/Turing/izlov/src/inference/hmc.jl:133",
      " [6] sample(::Turing.Model{Tuple{:logits},Tuple{:y},getfield(Main, Symbol(\"###inner_function#395#17\")){Array{Real,2},Int64},NamedTuple{(:y,),Tuple{Array{Float64,1}}},NamedTuple{(:y,),Tuple{Symbol}}}, ::NUTS{Turing.Core.ForwardDiffAD{40},Union{}}) at /home/sheshank/.julia/packages/Turing/izlov/src/inference/hmc.jl:108",
      " [7] top-level scope at In[12]:3"
     ]
    }
   ],
   "source": [
    "n_obs, n_vars = size(X_train)\n",
    "model = gp_classification(X_train, y_train, n_obs)\n",
    "chain = sample(model, NUTS(1500, 200, 0.65));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[8]:1"
     ]
    }
   ],
   "source": [
    "plot(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: chain not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: chain not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[9]:1"
     ]
    }
   ],
   "source": [
    "describe(chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
