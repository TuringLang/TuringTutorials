---
title: Getting Started
permalink: /docs/using-turing/get-started
redirect_from: docs/0-gettingstarted/
weave_options:
  error : false
---

# Getting Started

## Installation

To use Turing, you need to install Julia first and then install Turing.

### Install Julia

You will need to install Julia 1.3 or greater, which you can get from [the official Julia website](http://julialang.org/downloads/).

### Install Turing.jl

Turing is an officially registered Julia package, so you can install a stable version of Turing by running the following in the Julia REPL:

```julia
using Pkg
Pkg.add("Turing")
```

You can check if all tests pass by running `Pkg.test("Turing")` (it might take a long time)

## Example

Here's a simple example showing Turing in action.

First, we can load the Turing and StatsPlots modules

```julia
using Turing
using StatsPlots
```

Then, we define a simple Normal model with unknown mean and variance

```julia
@model function gdemo(x, y)
    s² ~ InverseGamma(2, 3)
    m ~ Normal(0, sqrt(s²))
    x ~ Normal(m, sqrt(s²))
    return y ~ Normal(m, sqrt(s²))
end
```

Then we can run a sampler to collect results. In this case, it is a Hamiltonian Monte Carlo sampler

```julia
chn = sample(gdemo(1.5, 2), HMC(0.1, 5), 1000)
```

We can plot the results

```julia
plot(chn)
```

In this case, because we use the [normal-inverse gamma distribution](https://en.wikipedia.org/wiki/Normal-inverse-gamma_distribution)
as a [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior), we can compute
its updated mean as follows:

```julia
s² = InverseGamma(2, 3)
m = Normal(0, 1)
data = [1.5, 2]
x_bar = mean(data)
N = length(data)

mean_expectation = (m.σ * m.μ + N * x_bar) / (m.σ + N)
```

We can also compute the updated variance

```julia
updated_alpha = shape(s²) + (N / 2) 
updated_beta = scale(s²) + (1/2) * sum((data[n] - x_bar)^2 for n in 1:N) + (N * m.σ)/(N + m.σ) * ((x_bar)^2)/2

variance_expectation = updated_beta / (updated_alpha - 1)
```

Finally, we can check if these expectations align with our approximations

```julia
# Visualize a blue density plot of the mean approximate posterior distribution
density(group(chn, :m); legend=:best, label="Posterior for m (HMC)", w=2, c=:blue)

# Visualize the true posterior mean in red
vline!([mean_expectation]; label="Posterior for m (Analytical)", c=:red)
```

```julia
# Visualize a blue density plot of the variance approximate posterior distribution
density(group(chn, :s²); legend=:best, label="Posterior for s² (HMC)", w=2, c=:blue)

# Visualize the true posterior mean in red
vline!([variance_expectation]; label="Posterior for s² (Analytical)", c=:red)
```
